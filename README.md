# ğŸš€ Despliegue de Infraestructura Cloud (IaC) & CI/CD

**Rama:** `feature/infra-ci-ale`
**Responsable:** Alejandro Nelson Herrera Soria
**Tickets Asociados:** `KAN-35` (Terraform Infra), `KAN-33` (CI/CD)

## ğŸ“‘ Tabla de Contenidos

1.  [Resumen Ejecutivo](https://www.google.com/search?q=%23-resumen-ejecutivo)
2.  [Arquitectura y Decisiones de DiseÃ±o](https://www.google.com/search?q=%23-arquitectura-y-decisiones-de-dise%C3%B1o)
3.  [Detalle de ImplementaciÃ³n: Infraestructura (Terraform)](https://www.google.com/search?q=%23-detalle-de-implementaci%C3%B3n-infraestructura-terraform)
4.  [Detalle de ImplementaciÃ³n: CI/CD Pipeline](https://www.google.com/search?q=%23-detalle-de-implementaci%C3%B3n-cicd-pipeline)
5.  [DesafÃ­os TÃ©cnicos y Soluciones](https://www.google.com/search?q=%23-desaf%C3%ADos-t%C3%A9cnicos-y-soluciones-troubleshooting)
6.  [Estructura del CÃ³digo](https://www.google.com/search?q=%23-estructura-del-c%C3%B3digo)

-----

## ğŸ“‹ Resumen Ejecutivo

Esta rama marca la transiciÃ³n del proyecto hacia un entorno de nube profesional. Se ha implementado **Infraestructura como CÃ³digo (IaC)** utilizando **Terraform** para aprovisionar una flota de servidores EC2 optimizados para Ingesta, OrquestaciÃ³n y Procesamiento en AWS (RegiÃ³n Ohio `us-east-2`).

Adicionalmente, se ha establecido un flujo de **IntegraciÃ³n Continua (CI)** mediante **GitHub Actions** que valida la calidad del cÃ³digo en todas las ramas de desarrollo, asegurando estÃ¡ndares de Python alineados con la infraestructura desplegada.

-----

## ğŸ— Arquitectura y Decisiones de DiseÃ±o

### 1\. CÃ³mputo Especializado (EC2 Fleet)

En lugar de una arquitectura genÃ©rica, diseÃ±amos una flota de instancias optimizada por funciÃ³n para balancear **Rendimiento vs. Costo**:

  * **API de Ingesta:** Instancia `t3.micro`. Aprovecha la capa gratuita para servicios ligeros de entrada de datos.
  * **Orquestador (Airflow):** Instancia **`c7i-flex.large`** (Compute Optimized) con **4GB RAM**.
      * *DecisiÃ³n:* Se escalÃ³ a esta instancia para soportar la carga concurrente de mÃºltiples DAGs sin latencia.
      * *Almacenamiento:* Disco **EBS gp3 de 30GB** para manejar logs y metadatos sin saturaciÃ³n.
  * **Worker de Procesamiento (Spark):** Instancia **`m7i-flex.large`** (General Purpose) con **8GB RAM**.
      * *DecisiÃ³n:* Necesaria para manejar cargas de trabajo intensivas en memoria durante la transformaciÃ³n de datos (Huella HÃ­drica).
      * *Almacenamiento:* Disco **EBS gp3 de 50GB** para soportar el "spill to disk" de Spark y almacenamiento de imÃ¡genes Docker.

### 2\. Aprovisionamiento Automatizado (Zero-Touch Provisioning)

Se eliminÃ³ la configuraciÃ³n manual de servidores. Mediante el uso de **Terraform `user_data`**, todas las instancias se despliegan con un script de inicializaciÃ³n (`install_docker.sh`) que:

  * Actualiza el sistema operativo (Ubuntu 22.04).
  * Instala **Docker** y **Docker Compose**.
  * Configura permisos de usuario y Git.
  * *Beneficio:* El equipo puede empezar a trabajar inmediatamente despuÃ©s del despliegue sin perder tiempo configurando entornos.

### 3\. Calidad de CÃ³digo Automatizada

Se implementÃ³ un pipeline de CI agnÃ³stico al entorno local:

  * **ValidaciÃ³n Multi-rama:** El pipeline se ejecuta en cualquier branch (`**`), no solo en `main`, previniendo la integraciÃ³n de cÃ³digo defectuoso desde etapas tempranas.
  * **Entorno de ProducciÃ³n Simulado:** Los tests corren sobre **Python 3.10**, replicando la versiÃ³n nativa de los servidores Ubuntu 22.04 en AWS.

-----

## ğŸ›  Detalle de ImplementaciÃ³n: Infraestructura (Terraform)

El cÃ³digo de infraestructura se encuentra en el directorio `infra/` y sigue un enfoque modular:

  * **`compute.tf`**: Define la creaciÃ³n de las 3 instancias EC2, asignaciÃ³n de discos `gp3`, inyecciÃ³n de scripts `user_data` y asociaciÃ³n de Security Groups.
  * **`iam.tf`**: Gestiona Roles y Perfiles de Instancia (IAM) para permitir que los servidores accedan a S3 sin necesidad de hardcodear credenciales (AWS Access Keys) en el cÃ³digo.
  * **`storage.tf`**: Define la estructura del Data Lake en S3 (Buckets y carpetas para capas Bronze/Silver/Gold).
  * **`variables.tf`**: Centraliza la configuraciÃ³n (RegiÃ³n, AMIs, Tipos de Instancia), permitiendo cambios rÃ¡pidos de hardware sin tocar el cÃ³digo lÃ³gico.
  * **`provider.tf`**: ConfiguraciÃ³n del proveedor AWS y versiones de Terraform.
  * **`install_docker.sh`**: Script Bash inyectado en las instancias al momento del arranque (`boot`).

-----

## ğŸ”„ Detalle de ImplementaciÃ³n: CI/CD Pipeline

Se configurÃ³ un Workflow de GitHub Actions (`.github/workflows/ci.yml`) estricto:

**Pasos del Pipeline:**

1.  **Trigger:** Push o Pull Request hacia cualquier rama.
2.  **Setup:** Levanta contenedor Ubuntu con Python 3.10.
3.  **Linter:** Ejecuta `flake8` para auditar sintaxis y deuda tÃ©cnica.
4.  **Testing:** Ejecuta `pytest` con descubrimiento automÃ¡tico de tests.
5.  **Quality Gate:** Si algÃºn paso falla, se bloquea la posibilidad de hacer Merge en GitHub.

-----

## ğŸ’¥ DesafÃ­os TÃ©cnicos y Soluciones

Durante la fase de infraestructura nos enfrentamos a desafÃ­os de gestiÃ³n de estado y seguridad:

| DesafÃ­o / Error | Causa RaÃ­z | SoluciÃ³n Implementada |
| :--- | :--- | :--- |
| **InvalidKeyPair.NotFound** | Terraform intentaba usar una llave SSH creada en una regiÃ³n distinta o inexistente en `us-east-2`. | UnificaciÃ³n del nombre de la llave en `variables.tf` y recreaciÃ³n del KeyPair en la regiÃ³n correcta (Ohio). |
| **Bloqueo por Disco Lleno** | Las instancias por defecto (8GB) fallaban al levantar contenedores Docker pesados y logs de Spark. | ImplementaciÃ³n de bloques `root_block_device` en Terraform para aprovisionar discos **gp3** de 30GB y 50GB. |
| **ConfiguraciÃ³n Manual Repetitiva** | Cada reinicio de instancia requerÃ­a instalar librerÃ­as manualmente. | AutomatizaciÃ³n vÃ­a `user_data` con script Bash para instalar Docker/Git al inicio (`boot time`). |
| **GestiÃ³n de Estado (State Lock)** | Riesgo de conflictos al trabajar infraestructura en equipo sin un Backend remoto. | Estrategia de **Code Freeze** para el Sprint 1 y uso de `terraform import` planificado para sincronizar recursos existentes (S3) en el Sprint 2. |

-----

## ğŸ“‚ Estructura del CÃ³digo

```text
huella-hidrica/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml          # Pipeline de Calidad (GitHub Actions)
â”œâ”€â”€ infra/                  # Infraestructura como CÃ³digo (Terraform)
â”‚   â”œâ”€â”€ .terraform/         # Binarios de proveedores (Ignorado en git)
â”‚   â”œâ”€â”€ compute.tf          # DefiniciÃ³n de EC2 y Discos
â”‚   â”œâ”€â”€ iam.tf              # Permisos y Roles
â”‚   â”œâ”€â”€ install_docker.sh   # Script de automatizaciÃ³n (User Data)
â”‚   â”œâ”€â”€ provider.tf         # ConfiguraciÃ³n AWS
â”‚   â”œâ”€â”€ storage.tf          # DefiniciÃ³n de S3 (Data Lake)
â”‚   â”œâ”€â”€ variables.tf        # Variables de configuraciÃ³n
â”‚   â””â”€â”€ terraform.tfstate   # Estado local (Ignorado en git)
â”œâ”€â”€ .gitignore              # Exclusiones
â””â”€â”€ README.md               # Esta documentaciÃ³n
```
